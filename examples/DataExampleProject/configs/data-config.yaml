# TODO

# TODO: start from this:
ingestion:
- name: "firm"
  path: "firm_synthetic.csv"
  format: "csv"
  date_column: { "date": "%Y%m%d" }
  firm_id_column: "permco"
  to_lowercase_cols: true
- name: "macro"
  path: "macro_synthetic.csv"
  format: "csv"
  date_column: { "date": "%Y%m%d" }
  to_lowercase_cols: true

wrangling_pipeline:
- operation: "monthly_imputation"
  dataset: "firm"
  numeric_columns: [ "volume", "marketcap" ]
  categorical_columns: []
  output_name: "imputed_firm"

- operation: "scale_to_range"
  dataset: "imputed_firm"
  range: { min: -1, max: 1 }
  cols_to_scale: [ "volume", "marketcap" ]
  output_name: "scaled_firm"

- operation: "merge"
  left_dataset: "scaled_firm"
  right_dataset: "macro"
  "on": [ "date" ]
  how: "left"
  output_name: "firm_and_macro"

- operation: "lag"
  dataset: "firm_and_macro"
  periods: 1
  columns_to_lag:
  - method: "all_except"
  - columns: [ "date", "permco", "return" ]
  drop_original_cols_after_lag: true
  restore_names: true # true to restore original column names after lagging (raise an error if drop_original_cols_after_lag is false and restore_names is true)
  drop_generated_nans: true # true to drop rows with NaN values generated by lagging
  output_name: "lagged_final"

- operation: "create_macro_interactions"
  dataset: "lagged_final"
  macro_columns: [ "gdp_growth", "cpi", "unemployment" ]
  firm_columns: [ "volume", "marketcap" ]
  drop_macro_columns: true # true to drop macro columns after creating interaction columns
  output_name: "interactions_dataset"

export:
- dataset_name: "lagged_final"
  output_filename_base: "final_dataset"
  format: "parquet"
  partition_by: "year" # year and none are the only values supported
